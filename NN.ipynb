{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550f2d1e-dfa8-4b20-ad1e-ed72da89f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d523e97b-3ed4-4e6b-b658-2c878bed9df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\harryqi\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\envs\\harryqi\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "D:\\Anaconda\\envs\\harryqi\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\\n%s\" %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count      1460.000000\n",
       "mean     180921.195890\n",
       "std       79442.502883\n",
       "min       34900.000000\n",
       "25%      129975.000000\n",
       "50%      163000.000000\n",
       "75%      214000.000000\n",
       "max      755000.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "data['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a51d3d3-c9d6-42ae-a51b-f5e883bd2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FcNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, num_classes, dropout=0.2):\n",
    "        super(FcNet, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.fc1 = nn.Linear(embedding_size*74, hidden_size) # 74 feature num\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.act_func = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = out.view(-1, 22*self.embedding_size)\n",
    "        out = self.fc1(out)\n",
    "        out = self.act_func(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.act_func(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        out = F.softmax(out, dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "513978d0-6509-4be0-890d-a3a130afdcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(x_path, y_path=None):\n",
    "    x_df = pd.read_csv(x_path)\n",
    "    X = []\n",
    "    for idx, row in x_df.iterrows():\n",
    "        # if idx == 1000:\n",
    "        #     break\n",
    "        feature = []\n",
    "        for col_key in row.keys():\n",
    "            if col_key != \"index\":\n",
    "                feature.append(row[col_key])\n",
    "        X.append(feature)\n",
    "    if y_path is None:\n",
    "        return X, None\n",
    "\n",
    "    y_df = pd.read_csv(y_path)\n",
    "    Y = []\n",
    "    for idx, row in y_df.iterrows():\n",
    "        # if idx == 1000:\n",
    "        #     break\n",
    "        Y.append(row[\"SalePrice\"])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c7ea171-c71e-423d-be02-774bd24a1738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(X):\n",
    "    dic = {}\n",
    "    for x in X:\n",
    "        for word in x:\n",
    "            if(word in dic):\n",
    "                dic[word] += 1\n",
    "            else:\n",
    "                dic[word] = 1\n",
    "    word_count_sorted = sorted(dic.items(), key=lambda item:item[1], reverse=True)\n",
    "    return  word_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c2e0652-9b45-4539-8328-0b4ac89f4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_index(X, vocab_size):\n",
    "    word_count_sorted = word_count(X)\n",
    "    word2index = {}\n",
    "    word2index[\"<unk>\"] = 0\n",
    "    word2index[\"<pad>\"] = 1\n",
    "    vocab_size = min(len(word_count_sorted), vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        word = word_count_sorted[i][0]\n",
    "        word2index[word] = i + 2\n",
    "    return word2index, vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6519e43a-cae8-4e58-8ab3-b140e06212ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(X, word2index):\n",
    "    features = []\n",
    "    for x in X:\n",
    "        feature = []\n",
    "        for word in x:\n",
    "            if word in word2index:\n",
    "                feature.append(word2index[word])\n",
    "            else:\n",
    "                feature.append(word2index[\"<unk>\"])\n",
    "        features.append(feature)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20a99235-e893-493c-9a0c-7dcc9fb15f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, Y=None, batch_size=128, do_shuffle=True):\n",
    "    num_batchs = int((len(X) - 1) / batch_size) + 1\n",
    "    indices = [idx for idx in range(len(X))]\n",
    "    if do_shuffle:\n",
    "        random.shuffle(indices)\n",
    "    batchs = []\n",
    "    for batch_num in range(num_batchs):\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = min((batch_num + 1) * batch_size, len(X))\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        for idx in range(start_index, end_index):\n",
    "            batch_x.append(X[indices[idx]])\n",
    "            if Y is not None:\n",
    "                label = [0, 0]\n",
    "                label[Y[indices[idx]]] = 1 # one hot label\n",
    "                batch_y.append(label)\n",
    "        batchs.append((batch_x, batch_y))\n",
    "    return batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bd72fde-fa03-4963-b47e-6aa680679eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dev(dataset):\n",
    "    train_set = []\n",
    "    dev_set = []\n",
    "    for data in dataset:\n",
    "        if random.random() > 0.2:\n",
    "            train_set.append(data)\n",
    "        else:\n",
    "            dev_set.append(data)\n",
    "    return train_set, dev_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e273791-9d31-4ef7-aae2-e7b69ed0d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dev_set, loss_func):\n",
    "    loss_val = 0.\n",
    "    data_size = 0\n",
    "    corrects = 0\n",
    "    for batch_x, batch_y in train_set:\n",
    "        datas = torch.LongTensor(batch_x)\n",
    "        labels = torch.FloatTensor(batch_y)\n",
    "\n",
    "        preds = model(datas)\n",
    "        loss = loss_func(preds, labels)\n",
    "\n",
    "        loss_val += loss.item() * datas.size(0)\n",
    "        data_size += datas.size(0)\n",
    "        \n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "        labels = torch.argmax(labels, dim=1)\n",
    "        corrects += torch.sum(preds == labels).item()\n",
    "\n",
    "    dev_loss = loss_val / (data_size + (1e-10))\n",
    "    dev_acc = corrects / (data_size + (1e-10))\n",
    "    print(\"Dev Loss: {}, Dev Acc: {}\".format(dev_loss, dev_acc))\n",
    "    return dev_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6726b73-c58f-442a-8598-5d7e779840d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_set, dev_set, vocab_size):\n",
    "    model = FcNet(vocab_size, 16, 32, 2)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
    "    loss_func = nn.BCELoss()\n",
    "\n",
    "    best_val_acc = 0.\n",
    "    best_model_params = copy.deepcopy(model.state_dict())\n",
    "    for epoch in range(1000):\n",
    "        loss_val = 0.\n",
    "        data_size = 0\n",
    "        corrects = 0\n",
    "        for batch_x, batch_y in train_set:\n",
    "            datas = torch.LongTensor(batch_x)\n",
    "            labels = torch.FloatTensor(batch_y)\n",
    "\n",
    "            preds = model(datas)\n",
    "            loss = loss_func(preds, labels)\n",
    "            l2_lambda = 0.0001\n",
    "            l2_reg = torch.tensor(0.)\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param)\n",
    "            loss += l2_lambda * l2_reg\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_val += loss.item() * datas.size(0)\n",
    "            data_size += datas.size(0)\n",
    "            \n",
    "            preds = torch.argmax(preds, dim=1)\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "            corrects += torch.sum(preds == labels).item()\n",
    "\n",
    "        train_loss = loss_val / (data_size + (1e-10))\n",
    "        train_acc = corrects / (data_size + (1e-10))\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Train Loss: {}, Train Acc: {}\".format(train_loss, train_acc))\n",
    "            test_acc = test(model, dev_set, loss_func)\n",
    "            if(best_val_acc < test_acc):\n",
    "                best_val_acc = test_acc\n",
    "                best_model_params = copy.deepcopy(model.state_dict()) # 更新最优参数\n",
    "    model.load_state_dict(best_model_params)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18ce9300-5e17-4610-9569-0d41dfb66201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, test_set):\n",
    "    results = [] \n",
    "    for batch_x, _ in test_set:\n",
    "        datas = torch.LongTensor(batch_x)\n",
    "        preds = model(datas)\n",
    "        preds = torch.argmax(preds, dim=1)\n",
    "        results += preds.tolist()\n",
    "    return results\n",
    "\n",
    "def post_process(file_path, results):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"pred\"] = results\n",
    "    df.to_csv(\"./results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d88fb854-c263-420f-96ba-078bb5181cbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-995bf8ef3331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mword2index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-5999a66a2664>\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(X, Y, batch_size, do_shuffle)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# one hot label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mbatchs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    do_train = True\n",
    "    if do_train:\n",
    "        X, Y = load_data(\"train_x.csv\", \"train_y.csv\")\n",
    "        word2index, vocab_size = word_index(X, 2000)\n",
    "        X = get_feature(X, word2index)\n",
    "        dataset = create_dataset(X, Y, 64)\n",
    "        train_set, dev_set = split_dev(dataset)\n",
    "        model = train(train_set, dev_set, vocab_size)\n",
    "        torch.save(model.state_dict(), \"./fc_net.pkl\")\n",
    "        print(\"train_size: \", len(train_set))\n",
    "        print(\"dev size: \", len(dev_set))\n",
    "    else:\n",
    "        X_train, _ = load_data(\"./x_train.csv\")\n",
    "        word2index, vocab_size = word_index(X_train, 2000)\n",
    "        X_test, _ = load_data(\"./test_x.csv\")\n",
    "        X_test = get_feature(X_test, word2index)\n",
    "        test_set = create_dataset(X_test, do_shuffle=False)\n",
    "        model = FcNet(vocab_size, 64, 128, 2)\n",
    "        model.load_state_dict(torch.load(\"./fc_net.pkl\"))\n",
    "        results = infer(model, test_set)\n",
    "        post_process(\"./test_x.csv\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029841ff-005a-454f-9ff2-ab3671f81f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
